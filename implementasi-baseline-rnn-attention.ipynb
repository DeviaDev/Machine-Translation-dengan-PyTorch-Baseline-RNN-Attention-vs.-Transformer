{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12856749,"sourceType":"datasetVersion","datasetId":8132015},{"sourceId":12858058,"sourceType":"datasetVersion","datasetId":8132781}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!ls -l /kaggle/input/translate6","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T02:15:12.317978Z","iopub.execute_input":"2025-08-25T02:15:12.318290Z","iopub.status.idle":"2025-08-25T02:15:12.471866Z","shell.execute_reply.started":"2025-08-25T02:15:12.318268Z","shell.execute_reply":"2025-08-25T02:15:12.470991Z"}},"outputs":[{"name":"stdout","text":"total 60\n-rw-r--r-- 1 nobody nogroup  3513 Aug 25 00:48 analisis.py\n-rw-r--r-- 1 nobody nogroup  1109 Aug 25 00:48 attention.py\n-rw-r--r-- 1 nobody nogroup  1521 Aug 25 00:48 decoder.py\n-rw-r--r-- 1 nobody nogroup   908 Aug 25 00:48 encoder.py\n-rw-r--r-- 1 nobody nogroup  9298 Aug 25 00:48 eval.py\n-rw-r--r-- 1 nobody nogroup  1738 Aug 25 00:48 heatmap.py\n-rw-r--r-- 1 nobody nogroup 11924 Aug 25 00:48 main.py\n-rw-r--r-- 1 nobody nogroup  3754 Aug 25 00:48 seq2seq.py\n-rw-r--r-- 1 nobody nogroup  2035 Aug 25 00:48 top_words.py\n-rw-r--r-- 1 nobody nogroup  5281 Aug 25 00:48 util.py\n","output_type":"stream"}],"execution_count":58},{"cell_type":"code","source":"import unicodedata\nfrom collections import Counter\nfrom pathlib import Path\nimport argparse\nimport json\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom tqdm import tqdm\nfrom torch.utils.data import Dataset, DataLoader\nimport math\nimport sacrebleu\nimport sys\nimport os\n\n# Definisikan konstanta global di luar fungsi\nSPECIALS = [\"<pad>\", \"<bos>\", \"<eos>\", \"<unk>\"]\nPAD, BOS, EOS, UNK = range(4)\n\n# --- Class Attention, Encoder, Decoder (sebagai contoh, pastikan Anda memiliki implementasi yang benar) ---\nclass BahdanauAttentionQKV(nn.Module):\n    def __init__(self, hidden_size, query_size, key_size, dropout_p=0.1):\n        super().__init__()\n        self.hidden_size = hidden_size\n        self.Wa = nn.Linear(query_size, hidden_size)\n        self.Wk = nn.Linear(key_size, hidden_size)\n        self.V = nn.Linear(hidden_size, 1)\n        self.dropout = nn.Dropout(p=dropout_p)\n\n    def forward(self, query, keys, mask=None):\n        # query: (batch_size, 1, hidden_size)\n        # keys: (batch_size, seq_len, hidden_size)\n        query = self.Wa(query)\n        keys = self.Wk(keys)\n        scores = self.V(torch.tanh(query + keys))\n        scores = scores.squeeze(-1)\n        if mask is not None:\n            scores.masked_fill_(mask, -float(\"inf\"))\n        return scores\n        \nclass BahdanauEncoder(nn.Module):\n    def __init__(self, input_dim, embedding_dim, encoder_hidden_dim, decoder_hidden_dim, dropout_p=0.1):\n        super().__init__()\n        self.embedding = nn.Embedding(input_dim, embedding_dim, padding_idx=PAD)\n        self.rnn = nn.GRU(embedding_dim, encoder_hidden_dim, bidirectional=True)\n        self.fc = nn.Linear(encoder_hidden_dim * 2, decoder_hidden_dim)\n        self.dropout = nn.Dropout(p=dropout_p)\n\n    def forward(self, src):\n        src_seq_len = src.shape[0]\n        embedded = self.dropout(self.embedding(src))\n        outputs, hidden = self.rnn(embedded)\n        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)))\n        return outputs, hidden\n\nclass BahdanauDecoder(nn.Module):\n    def __init__(self, output_dim, embedding_dim, encoder_hidden_dim, decoder_hidden_dim, attention, dropout_p=0.1):\n        super().__init__()\n        self.output_dim = output_dim\n        self.attention = attention\n        self.embedding = nn.Embedding(output_dim, embedding_dim, padding_idx=PAD)\n        self.rnn = nn.GRU(embedding_dim + encoder_hidden_dim * 2, decoder_hidden_dim)\n        self.fc_out = nn.Linear(embedding_dim + decoder_hidden_dim + encoder_hidden_dim * 2, output_dim)\n        self.dropout = nn.Dropout(p=dropout_p)\n        \n    def forward(self, x, hidden, encoder_outputs):\n        embedded = self.dropout(self.embedding(x))\n        \n        encoder_outputs_T = encoder_outputs.transpose(0, 1)\n        \n        query_for_attn = hidden.unsqueeze(1)\n        \n        attn_weights = self.attention(query_for_attn, encoder_outputs_T)\n        attn_weights = F.softmax(attn_weights, dim=1)\n        weighted_context = torch.bmm(attn_weights.unsqueeze(1), encoder_outputs_T).squeeze(1)\n\n        rnn_input = torch.cat((embedded.squeeze(0), weighted_context), dim=1).unsqueeze(0)\n        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n        \n        output = output.squeeze(0)\n        embedded = embedded.squeeze(0)\n        prediction = self.fc_out(torch.cat((output, weighted_context, embedded), dim=1))\n        \n        return prediction.unsqueeze(0), hidden.squeeze(0), attn_weights\n\n# ---- Class Model Seq2Seq dengan Beam Search ----\nclass BahdanauSeq2Seq(nn.Module):\n    def __init__(self, encoder, decoder, device, pad_id, bos_id, eos_id):\n        super().__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n        self.device = device\n        self.pad_id = pad_id\n        self.bos_id = bos_id\n        self.eos_id = eos_id\n\n    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n        trg_len, batch_size = trg.size()\n        outputs = torch.zeros(trg_len, batch_size, self.decoder.output_dim).to(self.device)\n        encoder_outputs, hidden = self.encoder(src)\n        trg_input = trg[0, :]\n\n        for t in range(1, trg_len):\n            output, hidden, _ = self.decoder(trg_input.unsqueeze(0), hidden, encoder_outputs)\n            outputs[t] = output.squeeze(0)\n            \n            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n            top1 = output.argmax(2).squeeze(0)\n            trg_input = trg[t] if teacher_force else top1\n            \n        return outputs, None\n\n    def greedy_decode(self, src, max_len=40):\n        batch_size = src.size(1)\n        encoder_outputs, hidden = self.encoder(src)\n        ys = torch.ones(1, batch_size, dtype=torch.long).fill_(self.bos_id).to(self.device)\n        \n        for _ in range(max_len - 1):\n            y_tm1 = ys[-1].unsqueeze(0)\n            output, hidden, _ = self.decoder(y_tm1, hidden, encoder_outputs)\n            \n            next_word_id = output.argmax(2)\n            \n            ys = torch.cat([ys, next_word_id], dim=0)\n\n        return ys, None\n\n    def beam_search_decode(self, src, max_len=40, beam_size=3):\n        batch_size = src.size(1)\n        encoder_outputs, hidden = self.encoder(src)\n        \n        hypotheses = torch.ones(1, batch_size, beam_size, dtype=torch.long).fill_(self.bos_id).to(self.device)\n        hyp_scores = torch.zeros(batch_size, beam_size).to(self.device)\n        \n        hidden_beams = hidden.unsqueeze(1).repeat(1, beam_size, 1)\n        hidden_beams = hidden_beams.view(batch_size * beam_size, -1)\n        \n        encoder_outputs_beams = encoder_outputs.transpose(0, 1).unsqueeze(1).repeat(1, beam_size, 1, 1).view(batch_size * beam_size, encoder_outputs.size(0), -1).transpose(0,1)\n\n        for _ in range(max_len - 1):\n            last_tokens = hypotheses[-1].view(-1, 1).transpose(0,1)\n            output, hidden_beams, _ = self.decoder(last_tokens, hidden_beams.view(batch_size * beam_size, -1), encoder_outputs_beams)\n            output = output.transpose(0, 1)\n            output = F.log_softmax(output, dim=-1)\n            \n            cand_scores = hyp_scores.unsqueeze(2) + output.view(batch_size, beam_size, -1)\n            \n            cand_scores, cand_indices = cand_scores.view(batch_size, -1).topk(beam_size, dim=-1)\n            \n            hyp_scores = cand_scores\n            \n            prev_hyp_indices = cand_indices // self.decoder.output_dim\n            new_token_indices = cand_indices % self.decoder.output_dim\n            \n            new_hypotheses = torch.zeros(hypotheses.size(0) + 1, batch_size, beam_size, dtype=torch.long).to(self.device)\n            for i in range(hypotheses.size(0)):\n                new_hypotheses[i] = torch.gather(hypotheses[i], 1, prev_hyp_indices)\n            new_hypotheses[-1] = new_token_indices\n            \n            hypotheses = new_hypotheses\n            \n            eos_mask = (new_token_indices == self.eos_id)\n            if eos_mask.all():\n                break\n\n        best_hyp_indices = hyp_scores.argmax(dim=1)\n        final_hypotheses = torch.zeros(max_len, batch_size, dtype=torch.long).to(self.device)\n\n        for b in range(batch_size):\n            best_hyp = hypotheses[:, b, best_hyp_indices[b]]\n            final_hypotheses[:len(best_hyp), b] = best_hyp\n            final_hypotheses[len(best_hyp):, b] = self.pad_id\n\n        return final_hypotheses.to(self.device)\n        \n# ---- Helper functions for data processing and evaluation ----\ndef normalize(text):\n    return unicodedata.normalize(\"NFKC\", text.lower().strip())\n\ndef to_ids(tokens, vocab, unk_id=3, bos_id=1, eos_id=2):\n    ids = [bos_id]\n    for tok in tokens:\n        ids.append(vocab.get(tok, unk_id))\n    ids.append(eos_id)\n    return ids\n\ndef decode_ids(ids, itos, bos_id=1, eos_id=2):\n    tokens = []\n    for i in ids:\n        if i.item() == eos_id:\n            break\n        if i.item() != bos_id:\n            tokens.append(itos[i.item()])\n    return \" \".join(tokens)\n\ndef collate_batch(batch):\n    src_list, trg_list = [], []\n    for src, trg in batch:\n        src_list.append(src)\n        trg_list.append(trg)\n    src_padded = torch.nn.utils.rnn.pad_sequence(src_list, batch_first=True, padding_value=PAD)\n    trg_padded = torch.nn.utils.rnn.pad_sequence(trg_list, batch_first=True, padding_value=PAD)\n    return src_padded, trg_padded\n\ndef load_pairs(file_path, max_len=20, max_pairs=None):\n    pairs = []\n    with open(file_path, 'r', encoding='utf-8') as f:\n        for i, line in enumerate(f):\n            if max_pairs and i >= max_pairs: break\n            parts = line.strip().split('\\t')\n            src, trg = normalize(parts[0]).split(' '), normalize(parts[1]).split(' ')\n            if len(src) < max_len and len(trg) < max_len:\n                pairs.append((src, trg))\n    return pairs\n\ndef split_pairs(pairs, train_ratio=0.8, val_ratio=0.1):\n    n = len(pairs)\n    n_train = int(n * train_ratio)\n    n_val = int(n * val_ratio)\n    return pairs[:n_train], pairs[n_train:n_train + n_val], pairs[n_train + n_val:]\n\ndef build_vocab(token_lists, min_freq=1, max_size=None, specials=SPECIALS):\n    counter = Counter()\n    for toks in token_lists:\n        counter.update(toks)\n    filtered = [(w, c) for w, c in counter.items() if c >= min_freq]\n    filtered.sort(key=lambda x: (-x[1], x[0]))\n    if max_size is not None:\n        filtered = filtered[:max(0, max_size - len(specials))]\n    vocab = {sp: i for i, sp in enumerate(specials)}\n    for w, _ in filtered:\n        if w not in vocab:\n            vocab[w] = len(vocab)\n    itos = {i: w for w, i in vocab.items()}\n    return vocab, itos\n\ndef epoch_run(model, loader, criterion, optimizer, train=True, teacher_forcing=0.5):\n    model.train() if train else model.eval()\n    total_loss, total_tokens = 0.0, 0\n    device = next(model.parameters()).device\n    \n    with torch.set_grad_enabled(train):\n        for src, trg in tqdm(loader):\n            src = src.to(device).T\n            trg = trg.to(device).T\n            \n            outputs, _att = model(src, trg, teacher_forcing_ratio=teacher_forcing if train else 0.0)\n            \n            logits = outputs[1:].reshape(-1, outputs.size(-1))\n            target = trg[1:].reshape(-1)\n            \n            loss = criterion(logits, target)\n            \n            if train:\n                optimizer.zero_grad(set_to_none=True)\n                loss.backward()\n                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n                optimizer.step()\n            \n            n_tokens = (target != PAD).sum().item()\n            total_loss += loss.item() * n_tokens\n            total_tokens += n_tokens\n            \n    avg_loss = total_loss / max(1, total_tokens)\n    ppl = math.exp(avg_loss) if avg_loss < 20 else float(\"inf\")\n    return avg_loss, ppl\n\ndef evaluate_sacrebleu(model, loader, trg_itos=None, sp_trg=None, beam_size=1):\n    model.eval()\n    refs, hyps = [], []\n    with torch.no_grad():\n        for src, trg in tqdm(loader):\n            src, trg = src.to(model.device).T, trg.to(model.device).T\n            if beam_size > 1:\n                ys = model.beam_search_decode(src, max_len=40, beam_size=beam_size)\n            else:\n                ys, _ = model.greedy_decode(src, max_len=40)\n            \n            if sp_trg:\n                pass\n            else:\n                for y in ys.T.tolist():\n                    hyps.append(decode_ids(torch.tensor(y), trg_itos))\n            \n            if sp_trg:\n                pass\n            else:\n                for t in trg.T.tolist():\n                    refs.append(decode_ids(torch.tensor(t), trg_itos))\n    \n    refs_sacrebleu = [[ref] for ref in refs]\n    bleu = sacrebleu.corpus_bleu(hyps, refs_sacrebleu).score\n    return bleu\n\n# ---- NMTDataset class ----\nclass NMTDataset(Dataset):\n    def __init__(self, pairs, src_vocab, trg_vocab):\n        self.data = [(to_ids(src, src_vocab), to_ids(trg, trg_vocab)) for src, trg in pairs]\n    def __len__(self):\n        return len(self.data)\n    def __getitem__(self, idx):\n        src_ids, trg_ids = self.data[idx]\n        return torch.tensor(src_ids, dtype=torch.long), torch.tensor(trg_ids, dtype=torch.long)\n\ndef main():\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    parser = argparse.ArgumentParser()\n    parser.add_argument('--data_path', type=str, default='/kaggle/input/translate5/ind-eng/ind.txt', help='Path to txt data')\n    parser.add_argument('--epochs', type=int, default=10, help='Number of training epochs')\n    parser.add_argument('--batch_size', type=int, default=32, help='Batch size')\n    parser.add_argument('--lr', type=float, default=1e-3, help='Learning rate')\n    parser.add_argument('--tf', type=float, default=0.5, help='Teacher Forcing')\n    parser.add_argument('--dropout', type=float, default=0.15, help='dropout')\n    parser.add_argument('--max_vocab', type=int, default=None)\n    parser.add_argument('--target_lang', type=str, default='ID', help='Bahasa tujuan')\n    parser.add_argument('--checkpoint', type=str, default='bahdanau_best.pt', help='Path to save model checkpoint')\n    \n    args, unknown = parser.parse_known_args()\n\n    data_file = Path(args.data_path)\n    pairs = load_pairs(data_file, max_len=20, max_pairs=None)\n    print(f\"Total usable pairs after filtering: {len(pairs):,}\")\n    train_pairs, val_pairs, test_pairs = split_pairs(pairs, 0.8, 0.1)\n    print(f\"Train: {len(train_pairs):,}, Val: {len(val_pairs):,}, Test: {len(test_pairs):,}\")\n\n    en_vocab, en_itos = build_vocab([src for src, _ in train_pairs], max_size=args.max_vocab)\n    id_vocab, id_itos = build_vocab([tgt for _, tgt in train_pairs], max_size=args.max_vocab)\n\n    with open(\"en_vocab.json\", \"w\") as f:\n        json.dump(en_vocab, f)\n    with open(\"id_vocab.json\", \"w\") as f:\n        json.dump(id_vocab, f)\n\n    print(f\"EN vocab size: {len(en_vocab):,} | ID vocab size: {len(id_vocab):,}\")\n    \n    train_ds = NMTDataset(train_pairs, en_vocab, id_vocab)\n    val_ds = NMTDataset(val_pairs, en_vocab, id_vocab)\n    test_ds = NMTDataset(test_pairs, en_vocab, id_vocab)\n\n    BATCH_SIZE = args.batch_size\n    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)\n    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_batch)\n    test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_batch)\n    \n    ENCODER_HIDDEN_SIZE = 512\n    DECODER_HIDDEN_SIZE = 256\n    ENCODER_EMBEDDING_DIM = 256\n    DECODER_EMBEDDING_DIM = 256\n\n    encoder = BahdanauEncoder(input_dim=len(en_vocab), embedding_dim=ENCODER_EMBEDDING_DIM, encoder_hidden_dim=ENCODER_HIDDEN_SIZE, decoder_hidden_dim=DECODER_HIDDEN_SIZE, dropout_p=args.dropout)\n    attn = BahdanauAttentionQKV(hidden_size=DECODER_HIDDEN_SIZE, query_size=DECODER_HIDDEN_SIZE, key_size=2 * ENCODER_HIDDEN_SIZE, dropout_p=0.0)\n    decoder = BahdanauDecoder(output_dim=len(id_vocab), embedding_dim=DECODER_EMBEDDING_DIM, encoder_hidden_dim=ENCODER_HIDDEN_SIZE, decoder_hidden_dim=DECODER_HIDDEN_SIZE, attention=attn, dropout_p=args.dropout)\n    \n    seq2seq = BahdanauSeq2Seq(encoder, decoder, device, pad_id=PAD, bos_id=BOS, eos_id=EOS).to(device)\n    criterion = nn.CrossEntropyLoss(ignore_index=PAD)\n    optimizer = torch.optim.Adam(seq2seq.parameters(), lr=args.lr)\n    \n    history = {\"train_loss\": [], \"val_loss\": [], \"train_ppl\": [], \"val_ppl\": [], \"val_bleu\": []}\n    EPOCHS = args.epochs\n    best_val = float(\"inf\")\n    \n    for epoch in range(1, EPOCHS + 1):\n        tf = max(0.3, 0.7 - 0.04 * (epoch - 1))\n        train_loss, train_ppl = epoch_run(seq2seq, train_loader, criterion, optimizer, train=True, teacher_forcing=tf)\n        val_loss, val_ppl = epoch_run(seq2seq, val_loader, criterion, optimizer, train=False, teacher_forcing=0.0)\n        \n        val_bleu = evaluate_sacrebleu(seq2seq, val_loader, trg_itos=id_itos)\n        \n        history[\"train_loss\"].append(train_loss)\n        history[\"val_loss\"].append(val_loss)\n        history[\"train_ppl\"].append(train_ppl)\n        history[\"val_ppl\"].append(val_ppl)\n        history[\"val_bleu\"].append(val_bleu)\n\n        print(f\"Epoch {epoch:02d} | TF={tf:.2f} | Train Loss {train_loss:.4f} PPL {train_ppl:.2f} | Val Loss {val_loss:.4f} PPL {val_ppl:.2f} | Val Bleu {val_bleu:.4f} \")\n\n        if val_loss < best_val:\n            best_val = val_loss\n            torch.save(seq2seq.state_dict(), args.checkpoint)\n            print(\"Saving best to\", args.checkpoint)\n\n    with open(\"train_history.csv\", \"w\", newline=\"\") as f:\n        w = csv.writer(f)\n        w.writerow([\"epoch\", \"train_loss\", \"val_loss\", \"train_ppl\", \"val_ppl\", \"val_bleu\"])\n        for i in range(EPOCHS):\n            w.writerow([i + 1, history[\"train_loss\"][i], history[\"val_loss\"][i], history[\"train_ppl\"][i], history[\"val_ppl\"][i], history[\"val_bleu\"][i]])\n\n    seq2seq.load_state_dict(torch.load(args.checkpoint, map_location=device))\n    test_loss, test_ppl = epoch_run(seq2seq, test_loader, criterion, optimizer, train=False, teacher_forcing=0.0)\n    \n    test_bleu = evaluate_sacrebleu(seq2seq, test_loader, trg_itos=id_itos, beam_size=3) \n    print(f\"TEST | Loss {test_loss:.4f} | PPL {test_ppl:.2f} | SacreBLEU {test_bleu:.2f}\")\n\n    references = []\n    hypotheses = []\n    seq2seq.eval()\n    with torch.no_grad():\n        n_show = 5\n        shown = 0\n        for src, trg in test_loader:\n            src = src.to(device).T\n            trg = trg.to(device).T\n\n            ys = seq2seq.beam_search_decode(src, max_len=40, beam_size=3)\n\n            B = src.size(1)\n            \n            for b in range(min(B, n_show - shown)):\n                src_txt = decode_ids(src[:, b], en_itos)\n                trg_txt = decode_ids(trg[:, b], id_itos)\n                pred_txt = decode_ids(ys[:, b], id_itos)\n                \n                references.append([trg_txt])\n                hypotheses.append(pred_txt)\n\n                if shown < n_show:\n                    print(\"-\" * 60)\n                    print(\"SRC :\", src_txt)\n                    print(\"TRG :\", trg_txt)\n                    print(\"PRED:\", pred_txt)\n                    shown += 1\n            \n            if shown >= n_show:\n                break\n    \n    bleu_final = sacrebleu.corpus_bleu(hypotheses, references).score\n    print(f\"Final BLEU score: {bleu_final:.2f}\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T02:15:12.526140Z","iopub.execute_input":"2025-08-25T02:15:12.526395Z","iopub.status.idle":"2025-08-25T02:17:30.832910Z","shell.execute_reply.started":"2025-08-25T02:15:12.526374Z","shell.execute_reply":"2025-08-25T02:17:30.832268Z"}},"outputs":[{"name":"stdout","text":"Total usable pairs after filtering: 14,856\nTrain: 11,884, Val: 1,485, Test: 1,487\nEN vocab size: 6,101 | ID vocab size: 6,884\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 372/372 [00:11<00:00, 33.19it/s]\n100%|██████████| 47/47 [00:00<00:00, 78.58it/s]\n100%|██████████| 47/47 [00:01<00:00, 30.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 01 | TF=0.70 | Train Loss 4.4330 PPL 84.19 | Val Loss 5.2005 PPL 181.36 | Val Bleu 42.7287 \nSaving best to bahdanau_best.pt\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 372/372 [00:11<00:00, 32.88it/s]\n100%|██████████| 47/47 [00:00<00:00, 78.52it/s]\n100%|██████████| 47/47 [00:01<00:00, 30.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 02 | TF=0.66 | Train Loss 2.3116 PPL 10.09 | Val Loss 4.8305 PPL 125.27 | Val Bleu 63.8943 \nSaving best to bahdanau_best.pt\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 372/372 [00:11<00:00, 32.43it/s]\n100%|██████████| 47/47 [00:00<00:00, 74.56it/s]\n100%|██████████| 47/47 [00:01<00:00, 30.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 03 | TF=0.62 | Train Loss 1.2729 PPL 3.57 | Val Loss 5.0060 PPL 149.30 | Val Bleu 33.4370 \n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 372/372 [00:11<00:00, 32.80it/s]\n100%|██████████| 47/47 [00:00<00:00, 78.97it/s]\n100%|██████████| 47/47 [00:01<00:00, 30.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 04 | TF=0.58 | Train Loss 0.9077 PPL 2.48 | Val Loss 5.2184 PPL 184.64 | Val Bleu 45.1801 \n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 372/372 [00:11<00:00, 33.15it/s]\n100%|██████████| 47/47 [00:00<00:00, 78.26it/s]\n100%|██████████| 47/47 [00:01<00:00, 30.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 05 | TF=0.54 | Train Loss 0.7535 PPL 2.12 | Val Loss 5.3817 PPL 217.40 | Val Bleu 25.8487 \n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 372/372 [00:11<00:00, 32.50it/s]\n100%|██████████| 47/47 [00:00<00:00, 79.24it/s]\n100%|██████████| 47/47 [00:01<00:00, 30.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 06 | TF=0.50 | Train Loss 0.6304 PPL 1.88 | Val Loss 5.4810 PPL 240.08 | Val Bleu 37.1501 \n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 372/372 [00:11<00:00, 33.24it/s]\n100%|██████████| 47/47 [00:00<00:00, 80.24it/s]\n100%|██████████| 47/47 [00:01<00:00, 30.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 07 | TF=0.46 | Train Loss 0.5613 PPL 1.75 | Val Loss 5.6574 PPL 286.41 | Val Bleu 45.1801 \n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 372/372 [00:11<00:00, 33.19it/s]\n100%|██████████| 47/47 [00:00<00:00, 79.02it/s]\n100%|██████████| 47/47 [00:01<00:00, 31.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 08 | TF=0.42 | Train Loss 0.5045 PPL 1.66 | Val Loss 5.7570 PPL 316.40 | Val Bleu 33.4370 \n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 372/372 [00:11<00:00, 33.14it/s]\n100%|██████████| 47/47 [00:00<00:00, 75.69it/s]\n100%|██████████| 47/47 [00:01<00:00, 30.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 09 | TF=0.38 | Train Loss 0.4649 PPL 1.59 | Val Loss 5.7414 PPL 311.49 | Val Bleu 29.0715 \n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 372/372 [00:11<00:00, 33.54it/s]\n100%|██████████| 47/47 [00:00<00:00, 79.24it/s]\n100%|██████████| 47/47 [00:01<00:00, 30.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10 | TF=0.34 | Train Loss 0.4535 PPL 1.57 | Val Loss 5.8773 PPL 356.83 | Val Bleu 29.0715 \n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 47/47 [00:00<00:00, 63.26it/s]\n100%|██████████| 47/47 [00:01<00:00, 32.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"TEST | Loss 6.1374 | PPL 462.83 | SacreBLEU 34.57\n------------------------------------------------------------\nSRC : i have something that i want to say to you.\nTRG : ada hal yang ingin aku katakan padamu.\nPRED: saya ada yang ingin aku ingin kuberitahukan\n------------------------------------------------------------\nSRC : i have to make the best of that small room.\nTRG : aku harus memanfaatkan ruang yang kecil itu <unk>\nPRED: saya harus pergi ke kamar kecil.\n------------------------------------------------------------\nSRC : i have to <unk> some cash from the bank.\nTRG : saya perlu mengambil uang di bank.\nPRED: saya harus menyelesaikan dari dari sepupu\n------------------------------------------------------------\nSRC : i just want to know what actually happened.\nTRG : aku hanya ingin mengetahui apa yang sebenarnya terjadi.\nPRED: aku hanya ingin tahu apa yang yang terjadi.\n------------------------------------------------------------\nSRC : i just wanted to check to see if you're ok.\nTRG : aku cuma ingin melihat apa kamu baik-baik saja.\nPRED: aku hanya ingin bertemu jika untuk yang ingin\nFinal BLEU score: 27.78\n","output_type":"stream"}],"execution_count":59}]}